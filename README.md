# ü§ñ An√°lise de Classifica√ß√£o de Spam com Machine Learning

## üìñ Sobre o Projeto

Este reposit√≥rio documenta uma jornada pr√°tica e educacional na constru√ß√£o de um modelo de machine learning para classificar e-mails como SPAM ou N√ÉO SPAM. O projeto foi desenvolvido a partir de um pequeno conjunto de dados manual e serve como um estudo de caso para explorar os desafios e as solu√ß√µes de problemas de classifica√ß√£o com machine learning, especialmente com recursos de dados limitados.

Este trabalho √© parte da disciplina de **Deep Learning e Machine Learning**, ministrada pelo Professor **Arthur Felipe da Silva Veloso**, no curso de **Engenharia de Computa√ß√£o com IA** do Centro Universit√°rio Tecnol√≥gico de Teresina - **UNI-CET**.

O objetivo principal n√£o √© criar o filtro de spam mais preciso do mundo, mas sim **entender como diferentes algoritmos funcionam, suas limita√ß√µes e o papel crucial dos dados no sucesso de um modelo**.

<img width="1000" height="699" alt="image" src="https://github.com/user-attachments/assets/f9eb5479-72a6-4d19-83fc-18c40bec2ec1" />

<img width="1280" height="960" alt="image" src="https://github.com/user-attachments/assets/d5a71a1b-65f7-4f42-9db3-43615d777741" />


## üöÄ Notebooks e Experimentos

O projeto √© dividido em cinco notebooks, cada um focado em um aspecto diferente da constru√ß√£o do modelo.

1.  **`01_Classificacao_Spam_Naives_Bayes.ipynb`**
    * **Prop√≥sito:** Estabelecer a linha de base (baseline) do nosso projeto usando um dos algoritmos mais cl√°ssicos e eficientes para detec√ß√£o de spam.
    * **Aprendizado:** Entender os conceitos de classifica√ß√£o bin√°ria, as suposi√ß√µes do Na√Øve Bayes e a import√¢ncia da Acur√°cia e Matriz de Confus√£o.

2.  **`02_Otimizacao_Limiar_Spam.ipynb`**
    * **Prop√≥sito:** Otimizar o modelo de Na√Øve Bayes sem adicionar novos dados, ajustando o limiar de probabilidade para reduzir Falsos Positivos.
    * **Aprendizado:** Descobrir que a acur√°cia nem sempre √© a melhor m√©trica e que o ajuste de hiperpar√¢metros (como o limiar) √© crucial para alinhar o modelo com as necessidades do neg√≥cio.

3.  **`03_Modelo_Semi_Supervisionado.ipynb`**
    * **Prop√≥sito:** Explorar uma abordagem alternativa de aprendizado (semi-supervisionado) para cen√°rios com poucos dados rotulados, simulando a adi√ß√£o de dados n√£o rotulados.
    * **Aprendizado:** Entender a diferen√ßa entre modelos supervisionados e semi-supervisionados e as limita√ß√µes de ambos quando a base de dados rotulada √© insuficiente.

4.  **`04_Arvore_Decisao_para_Classificacao.ipynb`**
    * **Prop√≥sito:** Testar a √Årvore de Decis√£o, um modelo supervisionado baseado em regras, para entender como ele lida com a classifica√ß√£o em um cen√°rio de dados limitados.
    * **Aprendizado:** Observar como um modelo focado em regras simples pode falhar em generalizar quando n√£o tem exemplos suficientes.

5.  **`05_Random_Forest_para_Classificacao.ipynb`**
    * **Prop√≥sito:** Avaliar um modelo mais complexo e poderoso (Random Forest) para ver se ele consegue superar o desempenho dos modelos anteriores com o mesmo conjunto de dados.
    * **Aprendizado:** Concluir que a complexidade do algoritmo n√£o garante melhor performance se a base de dados for pequena.

## üìà Conclus√µes Principais

Ap√≥s testar cinco abordagens diferentes, as principais conclus√µes do projeto s√£o:

1.  **Os Dados s√£o o Fator Limitante:** A performance do modelo, independentemente do algoritmo, foi diretamente limitada pela quantidade e variedade dos dados de treinamento.
2.  **A Simplicidade Venceu:** O modelo mais simples, **Na√Øve Bayes**, teve o melhor desempenho, mostrando que, para conjuntos de dados pequenos e espec√≠ficos, uma abordagem menos complexa pode ser a mais eficaz.
3.  **A Matriz de Confus√£o √© Essencial:** A an√°lise da matriz de confus√£o foi fundamental para identificar o problema real do nosso modelo (Falsos Positivos), algo que a acur√°cia sozinha n√£o revelaria.

Este projeto √© um excelente lembrete de que um cientista de dados n√£o se resume a escolher o algoritmo mais sofisticado, mas sim a entender profundamente os dados e as limita√ß√µes do problema em quest√£o.

## üõ†Ô∏è Requisitos

Para rodar os notebooks, voc√™ precisar√° das seguintes bibliotecas Python:
* `pandas`
* `scikit-learn`
* `numpy`
* `graphviz` (para visualizar a √Årvore de Decis√£o)

## ü§ù Como Contribuir

Sinta-se √† vontade para clonar este reposit√≥rio, testar com seus pr√≥prios dados ou sugerir melhorias.

---
Feito por Rafael Oliveira

Grupo: Rafael Oliveira, Maur√≠cio Lima, Paula Iranda, Get√∫lio Jos√© e Pedro Henrique
